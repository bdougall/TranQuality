{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "get_cos_Levenshtein.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E20cymTkY_eN"
      },
      "source": [
        "Install necessary packages for code to work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBhKv2QoY6xR",
        "outputId": "f31fd606-c0a1-46c7-bb32-2a7228205411"
      },
      "source": [
        "!pip install transformers -q\n",
        "!pip install sentencepiece -q"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.1 MB 8.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 72.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 18.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59 kB 8.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 56.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 6.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eYqYBl90F3k"
      },
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import editdistance\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import copy"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9kDvgc9-YQkz",
        "outputId": "888d4efb-c4ed-4f77-dc68-25675dabf468"
      },
      "source": [
        "# Leaving this for an example of how the input should look - language task column optional, but helpful\n",
        "# the rest of the column names are necessary for the code to work\n",
        "#df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>language_task</th>\n",
              "      <th>target_sentence</th>\n",
              "      <th>bart_translation</th>\n",
              "      <th>bart_paraphrase_score</th>\n",
              "      <th>indictrans_translation</th>\n",
              "      <th>indictrans_paraphrase_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>translate English to Hindi</td>\n",
              "      <td>प्रधानमंत्री ने कहा कि बाबा साहेब अम्बेडकर की ...</td>\n",
              "      <td>Prime Minister said Babasaheb Ambedkar has a k...</td>\n",
              "      <td>0.296427</td>\n",
              "      <td>प्रधानमंत्री ने कहा कि करोड़ों लोगों के दिलों ...</td>\n",
              "      <td>0.964050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>translate English to Hindi</td>\n",
              "      <td>इस समारोह को आज बीजापुर में आयोजित करने के महत...</td>\n",
              "      <td>आज बीजापुर में इस समारोह को आयोजित करने के महत...</td>\n",
              "      <td>0.961452</td>\n",
              "      <td>आज बीजापुर में इस कार्यक्रम के आयोजन के महत्व ...</td>\n",
              "      <td>0.975653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>translate English to Hindi</td>\n",
              "      <td>उन्होंने कहा कि इस कार्य को 2022 तक पूरा कर ले...</td>\n",
              "      <td>उन्होंने कहा कि लक्ष्य 2022 तक इस कार्य को पूर...</td>\n",
              "      <td>0.984172</td>\n",
              "      <td>उन्होंने कहा कि इस कार्य को 2022 तक पूरा करने ...</td>\n",
              "      <td>0.987264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>translate English to Hindi</td>\n",
              "      <td>प्रधानमंत्री ने कहा कि सरकार स्पष्ट लक्ष्यों औ...</td>\n",
              "      <td>प्रधानमंत्री ने कहा कि सरकार स्पष्ट लक्ष्यों औ...</td>\n",
              "      <td>0.987658</td>\n",
              "      <td>प्रधानमंत्री ने कहा कि सरकार स्पष्ट लक्ष्यों औ...</td>\n",
              "      <td>0.989116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>translate English to Hindi</td>\n",
              "      <td>उन्होंने इस संदर्भ में जन धन खाता खोलने, गरीबो...</td>\n",
              "      <td>इस संदर्भ में उन्होंने जनधन खाते खोलने, गरीबों...</td>\n",
              "      <td>0.979594</td>\n",
              "      <td>इस संदर्भ में उन्होंने जन धन खाते खोलने, गरीबो...</td>\n",
              "      <td>0.986208</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                language_task  ... indictrans_paraphrase_score\n",
              "0  translate English to Hindi  ...                    0.964050\n",
              "1  translate English to Hindi  ...                    0.975653\n",
              "2  translate English to Hindi  ...                    0.987264\n",
              "3  translate English to Hindi  ...                    0.989116\n",
              "4  translate English to Hindi  ...                    0.986208\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0f5_Z7J2KRJ"
      },
      "source": [
        "The mean_pooling and sentence_embeddings functions below are used to get the sentence embeddings for the cosine similarity scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJO_I2M5aimL"
      },
      "source": [
        "# Mean Pooling - Take attention mask into account for correct averaging\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0]\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "    return sum_embeddings / sum_mask\n",
        "\n",
        "def sentence_embeddings(device, tokenizer, model, sentences):\n",
        "  \"\"\"Create contextualized sentence embeddings\n",
        "  \n",
        "  Parameters:\n",
        "  tokenizer: transformers tokenizer for creating word tokens\n",
        "  model:\n",
        "  sentences: sentences to generate sentence embeddings for\n",
        "  \"\"\"\n",
        "\n",
        "  # Tokenize sentences and return PyTorch tensors\n",
        "  encoded_input = tokenizer(sentences, padding=True, truncation=True, \n",
        "                            max_length=128, return_tensors='pt')\n",
        "  encoded_input = encoded_input.to(device)\n",
        "  \n",
        "  # Pass the tokenized input to the model \n",
        "  with torch.no_grad():\n",
        "    model.to(device)\n",
        "    model_output = model(**encoded_input) \n",
        "  \n",
        "  # Perform mean pooling to get total sentence embeddings\n",
        "  sentence_embeddings = mean_pooling(model_output, \n",
        "                                     encoded_input['attention_mask'])\n",
        "  \n",
        "  return sentence_embeddings"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Op-TC2_2f4V"
      },
      "source": [
        "The check_cosine_similarity function is used to get cosine similarity scores between the target and the translation - I've used the following column names: target_sentence, bart_translation, and indictrans_translation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5Opaph2lQpN"
      },
      "source": [
        "# Get the sentence embeddings and cosine similarity scores between each pair of sentences in the dataset\n",
        "# This is to check if low scoring sentences have exact similarity scores or if they are of low quality\n",
        "def check_cosine_similarity(df, device, tokenizer, model):\n",
        "\n",
        "  # Create an empty list to check cosine similarity scores\n",
        "  bart_cos_scores = []\n",
        "  indictrans_cos_scores = []\n",
        "\n",
        "  for index, rows in df.iterrows():\n",
        "    # Get the sentence embeddings of each pair of target sentences\n",
        "    sent1_embed = sentence_embeddings(device, tokenizer, model, rows['target_sentence'])\n",
        "    sent2_embed = sentence_embeddings(device, tokenizer, model, rows['bart_translation'])\n",
        "    sent3_embed = sentence_embeddings(device, tokenizer, model, rows['indictrans_translation'])\n",
        "\n",
        "    # Reshape the embeddings to be of a single dimension \n",
        "    # Get the cosine similarity between the two pairs of sentence embeddings\n",
        "    bart_cosine_similarity_value = F.cosine_similarity(sent1_embed.squeeze(0), sent2_embed.squeeze(0), dim=0)\n",
        "    indictrans_cosine_similarity_value = F.cosine_similarity(sent1_embed.squeeze(0), sent3_embed.squeeze(0), dim=0)\n",
        "\n",
        "    # Add the cosine similarity scores to their respective lists\n",
        "    bart_cos_scores.append(bart_cosine_similarity_value.item())\n",
        "    indictrans_cos_scores.append(indictrans_cosine_similarity_value.item())\n",
        "\n",
        "  # Create two new columns in the dataframe to hold the respective scores\n",
        "  df['bart_cosine_score'] = bart_cos_scores\n",
        "  df['indictrans_cosine_score'] = indictrans_cos_scores\n",
        "\n",
        "  return df"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRwS1ZyJT8JK"
      },
      "source": [
        "def get_metrics(df):\n",
        "  \"\"\"A function that returns the dataframe with new columns for bart and indictrans cosine scores and edit distances\"\"\"\n",
        "\n",
        "  # Set up the device to run on GPU if available\n",
        "  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "  # Set the tokenizer and model as IndicBert Tokenizer and IndicBert model \n",
        "  tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert', keep_accents=True)\n",
        "  model = AutoModel.from_pretrained('ai4bharat/indic-bert')\n",
        "\n",
        "  # Get the cosine similarity scores for bart and indictrans\n",
        "  final = check_cosine_similarity(df, device, tokenizer, model)\n",
        "\n",
        "  # Get the edit distances for bart and indictrans\n",
        "  final['indictrans_edit'] = final.apply(lambda x: editdistance.eval(x['target_sentence'], x['indictrans_translation']), axis=1)\n",
        "  final['bart_edit'] = final.apply(lambda x: editdistance.eval(x['target_sentence'], x['bart_translation']), axis=1)\n",
        "\n",
        "  return final\n",
        "  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP4Y1guYYkzq",
        "outputId": "e2eebf08-22a3-4a73-90fc-ccf0643619c9"
      },
      "source": [
        "# Leaving this here so that you can see the function call\n",
        "# final = get_metrics(df)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertModel: ['predictions.LayerNorm.bias', 'sop_classifier.classifier.weight', 'predictions.decoder.weight', 'sop_classifier.classifier.bias', 'predictions.dense.weight', 'predictions.LayerNorm.weight', 'predictions.bias', 'predictions.decoder.bias', 'predictions.dense.bias']\n",
            "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "WmC3MA7saFLx",
        "outputId": "c9c54e1c-0d46-483c-aee6-dae23877a774"
      },
      "source": [
        "# Leaving this here so that you can see what the output should look like\n",
        "#final.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>language_task</th>\n",
              "      <th>target_sentence</th>\n",
              "      <th>bart_translation</th>\n",
              "      <th>bart_paraphrase_score</th>\n",
              "      <th>indictrans_translation</th>\n",
              "      <th>indictrans_paraphrase_score</th>\n",
              "      <th>bart_cosine_score</th>\n",
              "      <th>indictrans_cosine_score</th>\n",
              "      <th>indictrans_edit</th>\n",
              "      <th>bart_edit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>translate English to Hindi</td>\n",
              "      <td>प्रधानमंत्री ने कहा कि बाबा साहेब अम्बेडकर की ...</td>\n",
              "      <td>Prime Minister said Babasaheb Ambedkar has a k...</td>\n",
              "      <td>0.296427</td>\n",
              "      <td>प्रधानमंत्री ने कहा कि करोड़ों लोगों के दिलों ...</td>\n",
              "      <td>0.964050</td>\n",
              "      <td>0.770237</td>\n",
              "      <td>0.948379</td>\n",
              "      <td>67</td>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>translate English to Hindi</td>\n",
              "      <td>इस समारोह को आज बीजापुर में आयोजित करने के महत...</td>\n",
              "      <td>आज बीजापुर में इस समारोह को आयोजित करने के महत...</td>\n",
              "      <td>0.961452</td>\n",
              "      <td>आज बीजापुर में इस कार्यक्रम के आयोजन के महत्व ...</td>\n",
              "      <td>0.975653</td>\n",
              "      <td>0.946777</td>\n",
              "      <td>0.973164</td>\n",
              "      <td>56</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>translate English to Hindi</td>\n",
              "      <td>उन्होंने कहा कि इस कार्य को 2022 तक पूरा कर ले...</td>\n",
              "      <td>उन्होंने कहा कि लक्ष्य 2022 तक इस कार्य को पूर...</td>\n",
              "      <td>0.984172</td>\n",
              "      <td>उन्होंने कहा कि इस कार्य को 2022 तक पूरा करने ...</td>\n",
              "      <td>0.987264</td>\n",
              "      <td>0.956433</td>\n",
              "      <td>0.985965</td>\n",
              "      <td>3</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>translate English to Hindi</td>\n",
              "      <td>प्रधानमंत्री ने कहा कि सरकार स्पष्ट लक्ष्यों औ...</td>\n",
              "      <td>प्रधानमंत्री ने कहा कि सरकार स्पष्ट लक्ष्यों औ...</td>\n",
              "      <td>0.987658</td>\n",
              "      <td>प्रधानमंत्री ने कहा कि सरकार स्पष्ट लक्ष्यों औ...</td>\n",
              "      <td>0.989116</td>\n",
              "      <td>0.965325</td>\n",
              "      <td>0.986373</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>translate English to Hindi</td>\n",
              "      <td>उन्होंने इस संदर्भ में जन धन खाता खोलने, गरीबो...</td>\n",
              "      <td>इस संदर्भ में उन्होंने जनधन खाते खोलने, गरीबों...</td>\n",
              "      <td>0.979594</td>\n",
              "      <td>इस संदर्भ में उन्होंने जन धन खाते खोलने, गरीबो...</td>\n",
              "      <td>0.986208</td>\n",
              "      <td>0.979276</td>\n",
              "      <td>0.992806</td>\n",
              "      <td>38</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                language_task  ... bart_edit\n",
              "0  translate English to Hindi  ...       126\n",
              "1  translate English to Hindi  ...        43\n",
              "2  translate English to Hindi  ...        26\n",
              "3  translate English to Hindi  ...         3\n",
              "4  translate English to Hindi  ...        58\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}